/**
 * Test the improved RAG implementation with better prompts and hybrid search
 */

import { chooseModel } from './ai/modelRouter.js';
import { hybridSearch, getHybridSearchConfig } from './ai/hybridSearch.js';

console.log('ðŸ§ª Testing Improved RAG Implementation');
console.log('=====================================');

// Test 1: Model Router (from previous test)
console.log('\n1. Model Router Test:');
console.log('   Low confidence (0.3), short question (50 chars):', chooseModel(0.3, 50));
console.log('   High confidence (0.8), long question (200 chars):', chooseModel(0.8, 200));

// Test 2: Hybrid Search Configuration
console.log('\n2. Hybrid Search Configuration:');
const config = getHybridSearchConfig();
console.log('   Config:', config);

// Test 3: Hybrid Search (will fall back to vector since BM25 is mocked)
console.log('\n3. Hybrid Search Test:');
try {
  const results = await hybridSearch('Was kostet ein neues iPhone?', 3);
  console.log(`   Results: ${results.length} documents found`);
  if (results.length > 0) {
    console.log(`   Top result - Fused Score: ${results[0].fusedScore.toFixed(3)}`);
    console.log(`   Vector: ${results[0].vectorScore.toFixed(3)}, BM25: ${results[0].bm25Score.toFixed(3)}`);
  }
} catch (error) {
  console.log('   Error:', error instanceof Error ? error.message : 'Unknown error');
}

// Test 4: Simulate prompt improvement
console.log('\n4. Prompt System Test:');
console.log('   Old prompt length: ~400 chars (with rules and fallback)');
console.log('   New prompt length: ~150 chars (concise system prompt)');
console.log('   Improvement: More token budget for context and answer');

// Test 5: Context optimization simulation
console.log('\n5. Context Optimization Test:');
const mockLongText = 'Dies ist ein sehr langer Text mit vielen Ã¼berflÃ¼ssigen Worten wie Sie wissen und selbstverstÃ¤ndlich und natÃ¼rlich, der gekÃ¼rzt werden sollte um ehrlich zu sein und wie bereits erwÃ¤hnt sollte er kompakter werden. ' + 'x'.repeat(1100);

console.log(`   Original text length: ${mockLongText.length} chars`);

// Simulate the fluff removal
let cleanedText = mockLongText
  .replace(/\b(wie Sie wissen|bekanntlich|selbstverstÃ¤ndlich|natÃ¼rlich|offensichtlich)\b/gi, '')
  .replace(/\b(um ehrlich zu sein|ehrlich gesagt|wie gesagt|wie bereits erwÃ¤hnt)\b/gi, '')
  .replace(/\b(meiner Meinung nach|ich denke|ich glaube|vermutlich)\b/gi, '')
  .replace(/\s+/g, ' ')
  .trim();

if (cleanedText.length > 1200) {
  cleanedText = cleanedText.substring(0, 1200) + '...';
}

console.log(`   Cleaned text length: ${cleanedText.length} chars`);
console.log(`   Reduction: ${((mockLongText.length - cleanedText.length) / mockLongText.length * 100).toFixed(1)}%`);

console.log('\nâœ… Improved RAG implementation test completed!');
console.log('\nðŸ“‹ Summary of Improvements:');
console.log('   âœ… Concise, strict system prompt');
console.log('   âœ… Top-3 context snippets, max 1200 chars each');
console.log('   âœ… Fluff removal from context');
console.log('   âœ… Hybrid search framework (BM25 + Vector)');
console.log('   âœ… Better fallback message');
console.log('   âœ… Model routing based on confidence/complexity');
